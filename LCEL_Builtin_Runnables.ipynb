{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv \n",
    "_ = load_dotenv(find_dotenv()) \n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **RunnablePassthrough**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hitesh'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hitesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Runnable Lambda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name : str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda \n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hiteshovich'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hitesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Runnable Parallel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel \n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(), \n",
    "        \"operation_b\": RunnableLambda(russian_lastname)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'Hitesh', 'operation_b': 'Hiteshovich'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hitesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.prompts import ChatPromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {guy}\")\n",
    "\n",
    "output_parser = StrOutputParser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(), \n",
    "        \"guy\": RunnableLambda(russian_lastname_from_dictionary), \n",
    "        \"operation_c\": RunnablePassthrough()\n",
    "    }\n",
    ") | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daveovich is actually a fictional character created by author J.D. Salinger in his short story \"A Girl I Knew.\" The character is known for his eccentric and unpredictable behavior, making him a memorable figure in Salinger\\'s works.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name\": \"Dave\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel \n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings \n",
    "\n",
    "vector_store = FAISS.from_texts(\n",
    "    [\"The primary reason for applying for this job stems from my earnest desire to gain practical experience and further enhance my skills in Python. I am deeply passionate about Machine Learning, Deep Learning and Data Science and eager to immerse myself in real-world projects, working alongside seasoned professionals. This job presents an invaluable opportunity for me to translate theoretical knowledge into tangible outcomes, while also allowing me to contribute meaningfully to your team. I am enthusiastic about the chance to learn and grow within your esteemed organization, and I am committed to making the most of this valuable learning experience.\"], embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievers = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreival_chain = (\n",
    "    RunnableParallel({\"context\": retrievers, \"question\": RunnablePassthrough()}) \n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning and growing within the esteemed organization and making the most of the valuable learning experience.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreival_chain.invoke(\"I am enthusiastic about ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings \n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"The primary reason for applying for this job stems from my earnest desire to gain practical experience and further enhance my skills in Python. I am deeply passionate about Machine Learning, Deep Learning and Data Science and eager to immerse myself in real-world projects, working alongside seasoned professionals. This job presents an invaluable opportunity for me to translate theoretical knowledge into tangible outcomes, while also allowing me to contribute meaningfully to your team. I am enthusiastic about the chance to learn and grow within your esteemed organization, and I am committed to making the most of this valuable learning experience.\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever() \n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context: {context}\n",
    "Question : {question}\n",
    "\n",
    "Answer in the following language: {language} \n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\" : itemgetter(\"question\") | retrievers, \n",
    "        \"question\" : itemgetter(\"question\"), \n",
    "        \"language\" : itemgetter(\"language\"), \n",
    "    }\n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Este trabajo presenta una oportunidad invaluable para mí porque me permitirá adquirir experiencia práctica y mejorar mis habilidades en Python. También me brindará la oportunidad de sumergirme en proyectos del mundo real, trabajar junto a profesionales experimentados y contribuir significativamente al equipo.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":\"Why this job presents an invaluable opportunity for me\", \"language\" : \"spanish\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
